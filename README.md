ðŸŽ¨ Computer Vision for Interactive Museum Displays

An interactive real-time computer vision system that recognizes artworks using ORB feature extraction and descriptor matching, enabling adaptive and touch-free digital exhibit experiences.

ðŸ“Œ Overview

This project demonstrates how classical computer vision techniques can power interactive museum environments. The system detects and matches artworks in real time using feature extraction and similarity comparison, triggering dynamic digital responses based on visual recognition.

The solution is designed to simulate how modern museums can transition from static exhibits to immersive, AI-driven interactive displays.

ðŸš€ Key Features

Real-time artwork recognition using ORB feature extraction

Descriptor matching using OpenCVâ€™s BFMatcher

Webcam-based live detection pipeline

Dynamic response triggering based on similarity score

Optimized feature matching thresholds for stable recognition

ðŸ›  Tech Stack

Python

OpenCV

ORB (Oriented FAST and Rotated BRIEF)

NumPy

ðŸ§  System Architecture

The system follows the pipeline below:

Load reference artwork images

Extract ORB keypoints and descriptors from reference images

Capture live webcam frames

Extract ORB features from live frame

Perform descriptor matching using BFMatcher

Compute similarity score

Trigger digital display response if threshold is satisfied

ðŸ“Š Performance & Optimization

Real-time frame processing capability

Robust under moderate lighting variations

Optimized feature matching thresholds to reduce false positives

Lightweight classical CV approach suitable for low-resource systems
